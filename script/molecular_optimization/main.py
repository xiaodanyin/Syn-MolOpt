import json
import multiprocessing as mp
import time
from pathlib import Path
import os
import numpy as np
import pandas as pd
from tdc import Oracle
import pickle
from rdkit import Chem
from rdkit.Chem import Descriptors
import random
import torch
from synnet.config import MAX_PROCESSES
from synnet.data_generation.preprocessing import BuildingBlockFileHandler
from synnet.encoding.distances import cosine_distance, tanimoto_similarity
from synnet.models.common import find_best_model_ckpt, load_mlp_from_ckpt
from synnet.MolEmbedder import MolEmbedder
from synnet.utils.data_utils import ReactionSet
from synnet.utils.ga_utils import crossover, mutation
import sys
sys.path.append('./utils')
from predict_utils import mol_fp, syn_molopt_synthetic_tree_decoder
from property_func import Tox_Predictor_Mutag, Tox_Predictor_hERG, CYP_Predictor_CYP3A4, CYP_Predictor_CYP2C19

def check_file(args):

    output_file = args.output_file
    if not os.path.exists(output_file):
        os.makedirs(output_file)

    output_trees_file = args.output_trees_file
    if not os.path.exists(output_trees_file):
        os.makedirs(output_trees_file)   

def _fetch_molembedder(featurize: str):
    if featurize == "fp":
        return None  
    else:
        raise NotImplementedError

def func(emb):
    """
    Generates the synthetic tree for the input molecular embedding.

    Args:
        emb (np.ndarray): Molecular embedding to decode.

    Returns:
        str: SMILES for the final chemical node in the tree.
        SyntheticTree: The generated synthetic tree.
    """
    emb = emb.reshape((1, -1))  
    try:
        tree, action = syn_molopt_synthetic_tree_decoder(
            z_target=emb,
            building_blocks=building_blocks,
            bb_dict=bb_dict,
            reaction_templates=rxns[:91],
            functional_templates=rxns[91:len(rxns)],      
            mol_embedder=bblocks_molembedder.kdtree,  
            action_net=act_net,
            reactant1_net=rt1_net,
            rxn_net=rxn_net,
            reactant2_net=rt2_net,
            bb_emb=bb_emb,
            n_bits=args.nbits,
            max_step=15,
        )
    except Exception as e:
        print(e)
        action = -1
    if action != 3:
        return None, None
    else:
        scores = np.array(tanimoto_similarity(emb, [node.smiles for node in tree.chemicals]))
        scores_idx = np.array([1 if node.depth != 0 else 0 for node in tree.chemicals])
        mol_weight_idx = np.array([1 if mol_weight(node.smiles) <= 550 else 0 for node in tree.chemicals])
        scores = scores * scores_idx * mol_weight_idx
        max_score_idx = np.where(scores == np.max(scores))[0][0]
        print('Done with {}'.format(emb))
        return tree.chemicals[max_score_idx].smiles, tree

def mol_weight(smi):
    mol = Chem.MolFromSmiles(smi)
    mol_weight = Descriptors.MolWt(mol)
    return mol_weight

def gsk(smi):
    gsk_predictor = Oracle(name="GSK3B")
    if smi is None:
        return 0.0
    else:
        try:
            return gsk_predictor(smi)
        except:
            return 0.0

def mutag(smi):
    mutag_predictor = Tox_Predictor_Mutag()
    if smi is None:
        return 1.0
    else:
        try:
            return mutag_predictor.predict(smi)
        except:
            return 1.0

def hERG(smi):
    hERG_predictor = Tox_Predictor_hERG()
    if smi is None:
        return 1.0
    else:
        try:
            return hERG_predictor.predict(smi)
        except:
            return 1.0

def cyp3a4(smi):
    cyp3a4_predictor = CYP_Predictor_CYP3A4()
    if smi is None:
        return 1.0
    else:
        try:
            return cyp3a4_predictor.predict(smi)
        except:
            return 1.0

def cyp2c19(smi):
    cyp2c19_predictor = CYP_Predictor_CYP2C19()
    if smi is None:
        return 1.0
    else:
        try:
            return cyp2c19_predictor.predict(smi)
        except:
            return 1.0

def gsk_mutag(smi, act_c, tox_c):
    gsk_score = gsk(smi)
    mutag_score = mutag(smi)
    overall_score = act_c * gsk_score - tox_c * mutag_score
    return overall_score

def gsk_hERG(smi, act_c, tox_c):
    gsk_score = gsk(smi)
    hERG_score = hERG(smi)
    overall_score = act_c * gsk_score - tox_c * hERG_score
    return overall_score

def gsk_cyp3a4(smi, act_c, cyp_c):
    gsk_score = gsk(smi)
    cyp3a4_score = cyp3a4(smi)
    overall_score = act_c * gsk_score - cyp_c * cyp3a4_score
    return overall_score

def gsk_cyp2c19(smi, act_c, cyp_c):
    gsk_score = gsk(smi)
    cyp2c19_score = cyp2c19(smi)
    overall_score = act_c * gsk_score - cyp_c * cyp2c19_score
    return overall_score

def fitness(embs, obj):
    """
    Returns the scores for the root molecules in synthetic trees generated by the
    input molecular embeddings.

    Args:
        embs (list): Contains molecular embeddings (vectors).
        obj (str): The objective function to use to compute the fitness.

    Raises:
        ValueError: Raised if the specified objective function is not implemented.

    Returns:
        scores (list): Contains the scores for the root molecules in the
            generated trees.
        smiles (list): Contains the root molecules encoded as SMILES strings.
        trees (list): Contains the synthetic trees generated from the input
            embeddings.
    """
    results = []
    for emb in embs:
        result = func(emb)
        results.append(result)
    smiles = [r[0] for r in results]
    trees = [r[1] for r in results]

    if obj == "gsk":
        gsk = Oracle(name="GSK3B")
        scores = [gsk(smi) if smi is not None else 0.0 for smi in smiles]
    elif obj == "gsk_mutag":
        scores = [gsk_mutag(smi, args.act_c, args.tox_c) for smi in smiles]
    elif obj == "gsk_hERG":
        scores = [gsk_hERG(smi, args.act_c, args.tox_c) for smi in smiles]
    elif obj == "gsk_cyp3a4":
        scores = [gsk_cyp3a4(smi, args.act_c, args.cyp_c) for smi in smiles]
    elif obj == "gsk_cyp2c19":
        scores = [gsk_cyp2c19(smi, args.act_c, args.cyp_c) for smi in smiles]
    else:
        raise ValueError("Objective function not implemneted")
    
    return scores, smiles, trees

def distribution_schedule(n, total):

    if n < 4 * total / 5:
        return "linear"
    else:
        return "softmax_linear"

def num_mut_per_ele_scheduler(n, total):
    return 24

def mut_probability_scheduler(n, total):

    if n < total / 2:
        return 0.5
    else:
        return 0.5

def get_args():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--building-blocks-file",
        type=str,
        default="../../data/molecular_optimization/pre-process/building-blocks-rxns/filtered_building_block.csv.gz",
        help="Input file with SMILES strings (First row `SMILES`, then one per line).",
    )
    parser.add_argument(
        "--rxns-collection-file",
        type=str,
        default="../../data/molecular_optimization/pre-process/building-blocks-rxns/filtered_rxn_tpl_with_de-tox.json.gz",
        help="Input file for the collection of reactions matched with building-blocks.",
    )
    parser.add_argument(
        "--embeddings-knn-file",
        type=str,
        default="../../data/molecular_optimization/pre-process/embeddings/filtered_building_block_embeddings.npy",
        help="Input file for the pre-computed embeddings (*.npy).",
    )
    parser.add_argument(
        "--ckpt-dir", 
        type=str, 
        default="../../outputs/molopt/trained_models/tox_opt",
        help="Directory with checkpoints for {act,rt1,rxn,rt2}-model."
    )
    parser.add_argument(
        "--input-file",
        type=str,
        default="../../data/molecular_optimization/target_molecule/gsk3_mutag.csv",
        help="A file contains the molecules to be optimized.",
    )
    parser.add_argument(
        "--output_file",
        type=str,
        default='../../outputs/molopt/results',
        help="output dir.",
    )
    parser.add_argument(
        "--output_trees_file",
        type=str,
        default='../../outputs/molopt/syntrees',
        help="output dir.",
    )
    parser.add_argument(
        "--objective", 
        type=str, 
        default="gsk_mutag", 
        help="Choose from ['gsk_mutag', 'gsk_hERG', 'gsk_cyp3a4', 'gsk_cyp2c19']"
    )
    parser.add_argument(
        "--act_c", 
        type=float, 
        default="0.7", 
        help="The weight of the activity scoring function"
    )
    parser.add_argument(
        "--tox_c", 
        type=float, 
        default="0.3", 
        help="The weight of the toxicity scoring function"
    )    
    parser.add_argument(
        "--cyp_c", 
        type=float, 
        default="0.3", 
        help="The weight of the metabolic scoring function"
    ) 
    parser.add_argument(
        "--radius", 
        type=int, 
        default=2, 
        help="Radius for Morgan fingerprint."
    )
    parser.add_argument(
        "--nbits", 
        type=int, 
        default=4096, 
        help="Number of Bits for Morgan fingerprint."
    )
    parser.add_argument(
        "--featurize", 
        type=str, 
        default='fp'
    )
    parser.add_argument(
        "--num_population", 
        type=int, 
        default=128 if not debug else 4,         
        help="Number of parents sets to keep."
    )
    parser.add_argument(
        "--num_offspring",
        type=int,
        default=512 if not debug else 8,
        help="Number of offsprings to generate each iteration.",
    )
    parser.add_argument(
        "--num_gen", 
        type=int, 
        default=50 if not debug else 2, 
        help="Number of generations to proceed."
    )
    parser.add_argument("--ncpu", type=int, default=MAX_PROCESSES, help="Number of cpus")
    parser.add_argument(
        "--mut_probability",
        type=float,
        default=0.5,
        help="Probability to mutate for one offspring.",
    )
    parser.add_argument(
        "--num_mut_per_ele",
        type=int,
        default=1,
        help="Number of bits to mutate in one fingerprint.",
    )
    parser.add_argument("--restart", action="store_true")
    parser.add_argument("--seed", type=int, default=1, help="Random seed.")
    return parser.parse_args()

def fetch_population(args) -> np.ndarray:
    if args.restart:
        population = np.load(args.input_file)
        print(f"Starting with {len(population)} fps from {args.input_file}")
    else:
        if args.input_file is None:
            population = np.ceil(np.random.random(size=(args.num_population, args.nbits)) * 2 - 1)
            print(f"Starting with {args.num_population} fps with {args.nbits} bits")
        else:
            starting_smiles = pd.read_csv(args.input_file).sample(args.num_population)
            starting_smiles = starting_smiles["smiles"].tolist()
            population = np.array([mol_fp(smi, args.radius, args.nbits) for smi in starting_smiles])
            print(f"Starting with {len(starting_smiles)} fps from {args.input_file}")
    return population

def seed_torch(seed=1029):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

if __name__ == "__main__":
    
    debug = True

    args = get_args()
    check_file(args)
    seed_torch(args.seed)

    mol_embedder = _fetch_molembedder(args.featurize)
    bblocks_molembedder = (MolEmbedder().load_precomputed(args.embeddings_knn_file).init_balltree(cosine_distance))
    bb_emb = bblocks_molembedder.get_embeddings()
    building_blocks = BuildingBlockFileHandler().load(args.building_blocks_file)
    bb_dict = {block: i for i, block in enumerate(building_blocks)}
    rxns = ReactionSet().load(args.rxns_collection_file).rxns

    path = Path(args.ckpt_dir)
    ckpt_files = [find_best_model_ckpt(path / model) for model in "act rt1 rxn rt2".split()]
    act_net, rt1_net, rxn_net, rt2_net = [load_mlp_from_ckpt(file) for file in ckpt_files]

    population = fetch_population(args)
    with mp.Pool(processes=args.ncpu) as pool:
        scores, mols, trees = fitness(embs=population, obj=args.objective)
    scores = np.array(scores)
    score_x = np.argsort(scores)
    population = population[score_x[::-1]]
    mols = [mols[i] for i in score_x[::-1]]
    scores = scores[score_x[::-1]]
    print(f"Initial: {scores.mean():.3f} +/- {scores.std():.3f}")
    print(f"Scores: {scores}")
    print(f"Top-3 Smiles: {mols[:3]}")

    recent_scores = []
    for n in range(args.num_gen):
        t = time.time()

        dist_ = distribution_schedule(n, args.num_gen)
        num_mut_per_ele_ = num_mut_per_ele_scheduler(n, args.num_gen)
        mut_probability_ = mut_probability_scheduler(n, args.num_gen)

        offspring = crossover(
            parents=population, 
            offspring_size=args.num_offspring, 
            distribution=dist_
        )
        offspring = mutation(
            offspring_crossover=offspring,
            num_mut_per_ele=num_mut_per_ele_,
            mut_probability=mut_probability_,
        )
        new_population = np.unique(np.concatenate([population, offspring], axis=0), axis=0)
        with mp.Pool(processes=args.ncpu) as pool:
            new_scores, new_mols, trees = fitness(new_population, args.objective)
        new_scores = np.array(new_scores)
        scores = []
        mols = []

        parent_idx = 0
        indices_to_print = []
        while parent_idx < args.num_population:
            max_score_idx = np.where(new_scores == np.max(new_scores))[0][0]
            if new_mols[max_score_idx] not in mols:
                indices_to_print.append(max_score_idx)
                scores.append(new_scores[max_score_idx])
                mols.append(new_mols[max_score_idx])
                population[parent_idx, :] = new_population[max_score_idx, :]
                new_scores[max_score_idx] = -999999
                parent_idx += 1
            else:
                new_scores[max_score_idx] = -999999

        scores = np.array(scores)
        print(f"Generation {n+1}: {scores.mean():.3f} +/- {scores.std():.3f}")
        print(f"Scores: {scores}")
        print(f"Top-3 Smiles: {mols[:3]}")
        print(f"Consumed time: {(time.time() - t):.3f} s")
        print()
        for i in range(3):
            trees[indices_to_print[i]]._print()
        print()

        trees_top_128 = [trees[idx] for idx in indices_to_print]
        trees_file = os.path.join(args.output_trees_file, f'generation_{n + 1}_trees.pkl')
        with open(trees_file, 'wb') as file:
            pickle.dump(trees_top_128, file)
        
        recent_scores.append(scores.mean())
        if len(recent_scores) > 10:
            del recent_scores[0]

        np.save(os.path.join(args.output_file, "population_" + args.objective + "_" + str(n + 1) + ".npy"), population)

        data = {
            "objective": args.objective,
            "top1": np.mean(scores[:1]),
            "top10": np.mean(scores[:10]),
            "top100": np.mean(scores[:100]),
            "smiles": mols,
            "scores": scores.tolist(),
        }
        with open(os.path.join(args.output_file, "opt_" + args.objective + "_" + str(n + 1) + ".json"), "w") as f:
            json.dump(data, f)

        if n > 30 and recent_scores[-1] - recent_scores[0] < 0.01:
            print("Early Stop!")
            break

    data = {
        "objective": args.objective,
        "top1": np.mean(scores[:1]),
        "top10": np.mean(scores[:10]),
        "top100": np.mean(scores[:100]),
        "smiles": mols,
        "scores": scores.tolist(),
    }
    with open(os.path.join(args.output_file, "opt_" + args.objective + ".json"), "w") as f:
        json.dump(data, f)

    np.save(os.path.join(args.output_file, "population_" + args.objective + ".npy"), population)
